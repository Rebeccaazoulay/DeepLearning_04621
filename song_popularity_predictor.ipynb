{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7941127,"sourceType":"datasetVersion","datasetId":4668889},{"sourceId":7959916,"sourceType":"datasetVersion","datasetId":4682401},{"sourceId":8027982,"sourceType":"datasetVersion","datasetId":4731492},{"sourceId":8028272,"sourceType":"datasetVersion","datasetId":4731729},{"sourceId":8028289,"sourceType":"datasetVersion","datasetId":4731739}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# installments\n!pip install mamba_ssm","metadata":{"_uuid":"52318730-30b4-40a3-a2cc-8925146e257c","_cell_guid":"1db61640-88df-41c9-9eb0-9303afd79b38","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-04T20:15:48.651217Z","iopub.execute_input":"2024-04-04T20:15:48.651564Z","iopub.status.idle":"2024-04-04T20:16:22.935801Z","shell.execute_reply.started":"2024-04-04T20:15:48.651536Z","shell.execute_reply":"2024-04-04T20:16:22.934660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imports\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, Ridge, LinearRegression\nfrom sklearn.metrics import mean_squared_error, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom mamba_ssm import Mamba\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"_uuid":"8311d628-8e11-4a9c-bf3a-3b246892db74","_cell_guid":"129a8827-d67e-4ebd-afea-4ffbf171aebb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-04T20:16:22.938445Z","iopub.execute_input":"2024-04-04T20:16:22.938788Z","iopub.status.idle":"2024-04-04T20:16:30.613864Z","shell.execute_reply.started":"2024-04-04T20:16:22.938756Z","shell.execute_reply":"2024-04-04T20:16:30.613051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the dataset\ndataset_path = '/kaggle/input/spotifyaudiofeatures/SpotifyAudioFeaturesNov2018.csv'\n\nfeature_names = ['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness',\n                 'key', 'liveness', 'loudness', 'mode', 'speechiness', 'tempo',\n                 'time_signature', 'valence']\n\nsongs = pd.read_csv(dataset_path)\n\n# load features and target\nx = songs[feature_names].values\ny = songs['popularity'].values\n\nx_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3)\nx_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5)\n\nx_scaler = StandardScaler()\nx_scaler.fit(x_train)\nx_train = x_scaler.transform(x_train)\nx_test = x_scaler.transform(x_test)\n\n# create TensorDataset from numpy arrays`\nsongs_tensor_train_ds = TensorDataset(torch.tensor(x_train, dtype=torch.float).unsqueeze(1), torch.tensor(y_train, dtype=torch.float))\nsongs_tensor_val_ds = TensorDataset(torch.tensor(x_val, dtype=torch.float).unsqueeze(1), torch.tensor(y_val, dtype=torch.float))","metadata":{"_uuid":"47f7860c-b09b-4de4-99e9-947bb0d6284b","_cell_guid":"9394c7bd-f37c-461e-a20e-c11c8ef343b8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-04T20:16:30.614957Z","iopub.execute_input":"2024-04-04T20:16:30.615421Z","iopub.status.idle":"2024-04-04T20:16:31.383109Z","shell.execute_reply.started":"2024-04-04T20:16:30.615394Z","shell.execute_reply":"2024-04-04T20:16:31.382060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model, hyoer-paramerters\nclass MambaModel(nn.Module):\n    def __init__(self, input_dim, output_dim, d_state = 16, d_conv = 4, expand = 2):\n        super(MambaModel, self).__init__()\n        self.mamba = Mamba(\n        d_model=input_dim,\n        d_state=d_state,\n        d_conv=d_conv,\n        expand=expand\n        )\n        self.output_layer = nn.Linear(input_dim, output_dim)\n\n    def forward(self, x):\n        return self.output_layer(self.mamba(x))","metadata":{"_uuid":"aa6f7f08-bcd5-47d2-9076-e5dfadefbe74","_cell_guid":"61fee412-aa16-47c9-91fa-802795d2413d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-04T20:16:31.385363Z","iopub.execute_input":"2024-04-04T20:16:31.385706Z","iopub.status.idle":"2024-04-04T20:16:31.394592Z","shell.execute_reply.started":"2024-04-04T20:16:31.385664Z","shell.execute_reply":"2024-04-04T20:16:31.393693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define hyper-parmeters and create our model\nnum_features = x_train.shape[1]\noutput_dim = 1\nbatch_size = 128\nlearning_rate = 0.00001\nnum_epochs = 100\n#device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \n# loss criterion\ncriterion = nn.MSELoss()\n# model\nmodel = MambaModel(input_dim = num_features, output_dim = output_dim).to(device)\nprint(model)\n# optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)","metadata":{"_uuid":"66bd3d8f-7ddf-4e2f-b4a8-9f22d6f2c557","_cell_guid":"1e8c80b4-1398-48a8-bcbf-4aca700e2df2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-04T20:16:31.395815Z","iopub.execute_input":"2024-04-04T20:16:31.396114Z","iopub.status.idle":"2024-04-04T20:16:31.701142Z","shell.execute_reply.started":"2024-04-04T20:16:31.396090Z","shell.execute_reply":"2024-04-04T20:16:31.700154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensor_train_dataloader = DataLoader(songs_tensor_train_ds, batch_size=batch_size, shuffle=True)\nlosses = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_losses = []\n        \n    for features, target in tensor_train_dataloader:\n        # send data to device\n        features = features.to(device)\n        target = target.to(device)\n        # forward pass\n        output = model(features)\n        # loss\n        loss = criterion(output.view(-1), target)\n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        epoch_losses.append(loss.item())\n    if epoch%50 == 0:\n        print(f\"epoch: {epoch} loss: {np.mean(epoch_losses)}\")\n    losses.append(np.mean(epoch_losses))\n\nfig = plt.figure(figsize=(5, 5))\nplt.plot(losses)\nplt.grid(True)\nplt.title(\"Loss vs. Epochs\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()","metadata":{"_uuid":"2a415356-f236-4826-b0a9-5f89418623d0","_cell_guid":"f1b5d0bc-e40c-4354-a9dd-337e707d50fa","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-04T20:16:31.702306Z","iopub.execute_input":"2024-04-04T20:16:31.702661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing the model\nmodel.eval()\nwith torch.no_grad():\n    test_outputs = model(torch.tensor(x_test, dtype=torch.float, device=device).unsqueeze(1))\n    test_error = criterion(test_outputs.view(-1), torch.tensor(y_test, dtype=torch.float, device=device))\n    print(f\"Train error: {loss.item()}\")\n    print(f'Test error: {test_error.item()}')","metadata":{"_uuid":"c2298744-e6ac-432e-b238-694ab7d01375","_cell_guid":"36baddac-cd3a-4c6e-89b0-c4993bd1e9b7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"linReg = LinearRegression()\ny_pred = linReg.fit(x_train, y_train).predict(x_test)\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Test error: ', mse)\nregs_model = Ridge(alpha=1.0)\ny_pred2 = regs_model.fit(x_train, y_train).predict(x_test)\nmse = mean_squared_error(y_test, y_pred2)\nprint(f'Test error: ', mse)","metadata":{"_uuid":"67d9f376-c318-4200-b5b5-254995197f0b","_cell_guid":"eeee175f-37b8-46d9-aba6-6ebb1f734a4b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\n\n# Define the model\ndef define_model(trial):\n    d_state = trial.suggest_int(\"d_state\", 12, 20)\n    d_conv = trial.suggest_int(\"d_conv\", 2, 6)\n    expand = trial.suggest_int(\"expand\", 1, 4)\n    model = MambaModel(\n        d_state=d_state,\n        d_conv=d_conv,\n        expand=expand,\n        input_dim = num_features,\n        output_dim = 1\n    )\n    return model\n\n# Define the objective of the trial\ndef objective(trial):\n    # Generate the model.\n    model = define_model(trial).to(device)\n    # Generate the optimizers.\n    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n\n    criterion = nn.MSELoss()\n\n    # Get the training and the validation data\n    train_loader = DataLoader(songs_tensor_train_ds, batch_size=batch_size, shuffle=True)\n    valid_loader = DataLoader(songs_tensor_val_ds, batch_size=batch_size, shuffle=False)\n    \n    # Training of the model.\n    for epoch in range(num_epochs):\n        model.train()\n        for features, target in train_loader:\n            features = features.to(device)\n            target = target.to(device)\n            output = model(features)\n            loss = criterion(output.view(-1), target)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n    # Validation of the model\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for features, target in valid_loader:\n            features = features.to(device)\n            target = target.to(device)\n            output = model(features)\n            loss = criterion(output.view(-1), target)\n            total_loss += loss.item()\n\n    avg_loss = total_loss / len(valid_loader)\n    # report back to Optuna how far it is (epoch-wise) into the trial and how well it is doing (accuracy)\n    trial.report(avg_loss, epoch)\n\n    # then, Optuna can decide if the trial should be pruned\n    # Handle pruning based on the intermediate value\n    if trial.should_prune():\n        raise optuna.exceptions.TrialPruned()\n        \n    return avg_loss\n\n# Run the experiment\nstudy = optuna.create_study(study_name=\"mambaSpotify-fc\", direction=\"minimize\", sampler=optuna.samplers.TPESampler())\nstudy.optimize(objective, n_trials=100, timeout=600)\n\npruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\ncomplete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n\nprint(\"Study statistics: \")\nprint(\" Number of finished trials: \", len(study.trials))\nprint(\" Number of pruned trials: \", len(pruned_trials))\nprint(\" Number of complete trials: \", len(complete_trials))\n                   \nprint(\"Best trial:\")\ntrial = study.best_trial\n                   \nprint(\" Value: \", trial.value)\n                   \nprint(\" Params: \")\nfor key, value in trial.params.items():\n    print(\" {}: {}\".format(key, value))","metadata":{"_uuid":"a3963112-1cd8-41d3-b4be-c944e9e2002f","_cell_guid":"7c35fe36-cb8c-49c6-abb4-96e91f020a7f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}